{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, hidden_activation='sigmoid', output_activation='sigmoid'):\n",
    "        self.layers = []\n",
    "        layer_sizes = layers\n",
    "        \n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.layers.append(Linear(layer_sizes[i-1], layer_sizes[i]))\n",
    "            if i < len(layer_sizes) - 1:\n",
    "                self.layers.append(self.get_activation(hidden_activation))\n",
    "            else:\n",
    "                self.layers.append(self.get_activation(output_activation))\n",
    "    \n",
    "    def get_activation(self, activation):\n",
    "        if activation == 'sigmoid':\n",
    "            return Sigmoid()\n",
    "        elif activation == 'relu':\n",
    "            return ReLU()\n",
    "        elif activation == 'softmax':\n",
    "            return Softmax()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported activation function: {activation}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, loss):\n",
    "        for layer in reversed(self.layers):\n",
    "            loss = layer.backward(loss)\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate, loss_function='mse'):\n",
    "        for _ in range(epochs):\n",
    "            # Forward pass\n",
    "            output = self.forward(X)\n",
    "            \n",
    "            # Compute loss\n",
    "            if loss_function == 'mse':\n",
    "                loss_obj = MSELoss()\n",
    "                loss = loss_obj(output, y)\n",
    "            elif loss_function == 'crossentropy':\n",
    "                loss_obj = CrossEntropyLoss()\n",
    "                loss = loss_obj(output, y)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported loss function: {loss_function}\")\n",
    "            \n",
    "            # Backward pass\n",
    "            self.backward(loss_obj.backward())\n",
    "            \n",
    "            # Update parameters\n",
    "            for layer in self.layers:\n",
    "                if isinstance(layer, Linear):\n",
    "                    layer.weight -= learning_rate * layer.weight_grad\n",
    "                    layer.bias -= learning_rate * layer.bias_grad\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.weight = np.random.randn(in_features, out_features) * 0.01\n",
    "        self.bias = np.zeros((1, out_features))\n",
    "        self.weight_grad = np.zeros_like(self.weight)\n",
    "        self.bias_grad = np.zeros_like(self.bias)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        self.input = x\n",
    "        return np.dot(x, self.weight) + self.bias\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        self.weight_grad += np.dot(self.input.T, grad_output)\n",
    "        self.bias_grad += np.sum(grad_output, axis=0, keepdims=True)\n",
    "        return np.dot(grad_output, self.weight.T)\n",
    "\n",
    "class Sigmoid:\n",
    "    def __call__(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-x))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.output * (1 - self.output)\n",
    "\n",
    "class ReLU:\n",
    "    def __call__(self, x):\n",
    "        self.input = x\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (self.input > 0)\n",
    "\n",
    "class Softmax:\n",
    "    def __call__(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.output * (1 - self.output)\n",
    "\n",
    "class MSELoss:\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        self.diff = y_pred - y_true\n",
    "        return np.mean(self.diff**2)\n",
    "    \n",
    "    def backward(self):\n",
    "        return 2 * self.diff / self.diff.size\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __call__(self, y_pred, y_true):\n",
    "        self.y_pred = y_pred\n",
    "        self.y_true = y_true\n",
    "        return -np.sum(y_true * np.log(y_pred + 1e-8)) / y_true.shape[0]\n",
    "    \n",
    "    def backward(self):\n",
    "        return (self.y_pred - self.y_true) / self.y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.9667\n",
      "\n",
      "Sample predictions:\n",
      "True: versicolor, Predicted: versicolor\n",
      "True: setosa, Predicted: setosa\n",
      "True: virginica, Predicted: virginica\n",
      "True: versicolor, Predicted: versicolor\n",
      "True: versicolor, Predicted: versicolor\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_encoded = one_hot_encode(y_train, num_classes)\n",
    "y_test_encoded = one_hot_encode(y_test, num_classes)\n",
    "\n",
    "# Create and train the neural network\n",
    "nn_iris = NeuralNetwork(layers=[4, 10, 3], hidden_activation='relu', output_activation='softmax')\n",
    "nn_iris.train(X_train_scaled, y_train_encoded, epochs=1000, learning_rate=0.01, loss_function='crossentropy')\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = nn_iris.predict(X_test_scaled)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test_encoded, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_classes == true_classes)\n",
    "print(f\"Accuracy on test set: {accuracy:.4f}\")\n",
    "\n",
    "# Print some sample predictions\n",
    "print(\"\\nSample predictions:\")\n",
    "for i in range(5):\n",
    "    print(f\"True: {iris.target_names[true_classes[i]]}, Predicted: {iris.target_names[predicted_classes[i]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
